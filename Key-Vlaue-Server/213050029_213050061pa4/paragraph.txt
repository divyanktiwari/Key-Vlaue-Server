The Key-Value server is running multiple threads that contend for the shared Cache to access data quickly. As the load, which is taken as multiple requests that fired from multiple clients, the response time increases servers throughput reduces. The x-axis represesnts requests as product of number of clients and requests per client. We have attached a table below to see the exact specifications.
The major takeaways from the graph are that throughput saturates while each client sees an increasing delayed replies from the server with multple clients sending multiple requests. The likely reason for this is the effect of atomicity needed in cache entry that enforces single writer/ multiple reader synchronization. We have kept a BITMAP to track the empty locations in file, an INDEX which keeps track of location of keys within files (which allows us to directly seek to required position), and a global open file table to aid in quick IO. These are accessed inside mutexes which again causes bottlenecks in the server.
Due to these reasons the graph makes sense and shows the scalability of the server.
